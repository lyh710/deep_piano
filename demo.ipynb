{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, shutil\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# if gpu ready\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.utils as ku\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "from utils import midi_download\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_url=input('input_url:')\n",
    "print(input_url)\n",
    "midi_dir = input('midi_dir:')\n",
    "midi_dir = os.path.join(os.getcwd(), 'midi_download', midi_dir)\n",
    "print(midi_dir)\n",
    "midi_download.get_midi(input_url, midi_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU ready\n",
    "assert tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# Set model version\n",
    "# model_version = 'model.'+str(time())\n",
    "model_version = input('model version:')\n",
    "print(model_version)\n",
    "\n",
    "# Setup folder to output model\n",
    "model_dir = os.path.join(os.getcwd(), 'models')\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "out_dir = os.path.join(os.getcwd(), 'models', model_version)\n",
    "if os.path.isdir(out_dir):\n",
    "    shutil.rmtree(out_dir)\n",
    "os.mkdir(out_dir)\n",
    "\n",
    "data_dir = os.path.join(out_dir, 'data')\n",
    "os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a folder with midi files\n",
    "# midi_dir  = os.path.join(os.getcwd(), 'midi_all')\n",
    "midi_dir  = input('midi_dir:')\n",
    "midi_dir  = os.path.join(os.getcwd(), 'midi_download', midi_dir)\n",
    "print(midi_dir)\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir  = os.path.join(data_dir, 'test')\n",
    "utils.split_midi_train_test(midi_dir, train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notes = utils.midi_2_notes(os.path.join(test_dir, np.random.choice(os.listdir(test_dir))))\n",
    "print(output_notes)\n",
    "\n",
    "out_fn = os.path.join(test_dir, 'test_out.mid')\n",
    "utils.notes_2_midi(output_notes, out_fn, simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all the valid midi files in train folder into one csv corpus\n",
    "out_fn     = os.path.join(data_dir, 'corpus.csv')\n",
    "utils.midi_2_csv(train_dir, out_fn, small_f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- train -------------------------------------------\n",
    "corpus_fn    = os.path.join(data_dir, 'corpus.csv')\n",
    "assert os.path.exists(corpus_fn)\n",
    "df_corpus    = pd.read_csv(corpus_fn, header=None, names=['notes'])\n",
    "corpus_train = ' '.join(df_corpus['notes'].tolist())\n",
    "raw_notes    = corpus_train.split(' ')\n",
    "notes        = sorted(list(set(raw_notes)))\n",
    "note_2_int   = dict((n, i) for i, n in enumerate(notes))\n",
    "\n",
    "n_notes = len(raw_notes)\n",
    "n_vocab = len(notes)\n",
    "print('Total number of notes in training corpus: {}, number of unique note: {}'.format(n_notes, n_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_2_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_2_note = dict((i, n) for i, n in enumerate(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_2_note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we will split the entire training corpus into subsequences of 100 notes (an arbitrary fixed length)\n",
    "\n",
    "- Each training pattern of the network is comprised of 100 time steps of one note (X) followed by one note output (y). When creating these sequences, we slide this window along the training corpus one note at a time, allowing each note a chance to be learned from the 100 note that preceded it (except the first 100 note of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_notes - seq_length, 1):\n",
    "    seq_in  = raw_notes[i:i + seq_length]\n",
    "    seq_out = raw_notes[i + seq_length]\n",
    "    dataX.append([note_2_int[note] for note in seq_in])\n",
    "    dataY.append(note_2_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print('Total Patterns: {}'.format(n_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = ku.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# Callback: checkpoint\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "fn = os.path.join(out_dir, model_version+'_checkpoint_epoch.hdf5')\n",
    "checkpoint_epoch = ModelCheckpoint(fn, monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=100, batch_size=128, callbacks=[checkpoint_epoch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_fn    = os.path.join(test_dir, np.random.choice(os.listdir(test_dir)))\n",
    "# seed_fn    = os.path.join(os.getcwd(), 'midi', 'fur-elise.mid')\n",
    "print(seed_fn)\n",
    "seed_notes = utils.midi_2_notes(seed_fn).split(' ')\n",
    "# start      = np.random.randint(0, len(seed_notes)-seq_length)\n",
    "start      = 0\n",
    "pattern    = []\n",
    "for i in range(seq_length):\n",
    "    pattern.append(note_2_int[seed_notes[start+i]])\n",
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = []\n",
    "# for i in range(seq_length):\n",
    "#     pattern.append(np.random.choice(range(len(notes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = ' '.join([int_2_note[value] for value in pattern])\n",
    "print('Seed: {}'.format(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate notes\n",
    "generated = []\n",
    "for i in range(500):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_2_note[index]\n",
    "    generated.append(result)\n",
    "    seq_in = [int_2_note[value] for value in pattern]\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notes = start +' '+ ' '.join(generated)\n",
    "# output_notes = ' '.join(generated)\n",
    "print(output_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(out_dir,'generated.'+str(time())+'.mid')\n",
    "utils.notes_2_midi(output_notes, fn, simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# output the model to disk\n",
    "fn = os.path.join(out_dir, model_version+'.hdf5')\n",
    "if os.path.exists(fn):\n",
    "    os.remove(fn)\n",
    "model.save(fn)\n",
    "\n",
    "# output the history to disk\n",
    "fn = os.path.join(out_dir, model_version+'.history.pkl')\n",
    "utils.pkl_dump(history.history, fn)\n",
    "\n",
    "# Save the script\n",
    "src_fn = os.path.join(os.getcwd(), 'demo.ipynb')\n",
    "trg_fn = os.path.join(out_dir, 'demo.ipynb')\n",
    "if os.path.exists(trg_fn):\n",
    "    os.remove(trg_fn)\n",
    "shutil.copy(src_fn, trg_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "music"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
