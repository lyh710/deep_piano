# deep_piano
Piano music generation using deep learning.

## Aim
There are largely 2 ways to generate music:
- Generate the sound waves, which We tried and failed (https://github.com/lyh710/deep_piano/tree/music_as_time_series)
- Generate notation (sheet music), which we focused on here.

## Dev env
1. Windows 10 Home, i7 Core, 16GB ram (most subsequent steps should still hold true if with Mac/Linux, but some will need to be modified, such as the conda env setup batch)
2. NVIDIA GeForce GTX 1080 with Max-Q, 8GB (Google CoLab would be a good alternative)
3. conda env setup: dnn_gpu_setup_test\conda_dnn_gpu_setup.bat (Ananconda3)

## High level idea
Build a deep-learning model, with the "Transformer" architecture, which can take an input sequence of music notation and predict/generate the target sequence.

## Model work flow
1. music data acquired: midi_download.py
    - MIDI format
    - search online and download for study/research purpose only (http://midi.midicn.com/)

2. Convert MIDI file to sheet-music (notations), and vice versa, by employing the music21 package (https://web.mit.edu/music21/doc/index.html): see utils.py

3. Model training:

4. Piano music generated by:
    - Seed/Initial sound track is produced by:
        - Win10 Voice Recorder as m4a, which then convert to midi manually via: https://www.conversion-tool.com/audiotomidi/#uploadProgress